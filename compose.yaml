services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: >
      mlflow server
      --backend-store-uri file:///srv/mlruns
      --host 0.0.0.0
      --port 5000
      --serve-artifacts
      --artifacts-destination /srv/mlartifacts
    volumes:
      - ./mlruns:/srv/mlruns           # your existing runs/experiments
      - ./mlartifacts:/srv/mlartifacts # your model files, plots, etc.
    ports:
      - "5000:5000"

  app:
    build: .
    depends_on:
      - mlflow
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    ports:
      - "8000:8000"
